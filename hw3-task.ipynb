{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль 3. Домашняя работа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#=========библиотеки для подбора гиперпараметров============\n",
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import GridSearchCV\n",
    "    from sklearn.cross_validation import RandomizedSearchCV\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "#===========================================================\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import validation_curve\n",
    "except ImportError:\n",
    "    from sklearn.learning_curve import validation_curve\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "    \n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выборка для обучения - таргет присутствует\n",
    "df_train = pd.read_csv('train.csv', sep=',', encoding='utf8')\n",
    "#Выборка для валидации - таргет отсутствует\n",
    "df_valid = pd.read_csv('test.csv', sep=',', encoding='utf8')\n",
    "df_sample = pd.read_csv('sample_submission.csv', sep=',', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведем данные к виду, необходимому для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df_init):\n",
    "    df_output= df_init.copy()\n",
    "    \n",
    "    # Удалим ненужные признаки\n",
    "    df_output = df_output.drop(['_id', 'contact','day_of_week'], axis=1)\n",
    "    \n",
    "   # Кодируем категориальные признаки\n",
    "    df_output = pd.get_dummies(df_output, columns=['month','job','default', 'marital','education', 'housing', \\\n",
    "                                                  'loan', 'poutcome'])\n",
    "\n",
    "    #т.к. при значении данного атрибута больше 8 мало положительных значений, то пусть данные значения = 0 иначе 1\n",
    "    df_output['campaign'] = df_output['campaign'].map(lambda s: 0 if s>=8 else 1)\n",
    "    #повторяем для 'previous'\n",
    "    df_output['previous'] = df_output['previous'].map(lambda s: 0 if s>=4 else 1)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc_train = df_train.pipe(preproc) #получили необходимый для обучения датасет\n",
    "df_preproc_valid = df_valid.pipe(preproc) #получили датасет для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X - МАТРИЦА ПРИЗНАКОВ ДАННЫХ ДЛЯ ОБУЧЕНИЯ.\n",
    "# Удаляем таргет из фичей объектов, на которых проходим обучение\n",
    "X=df_preproc_train.drop('target', axis=1) \n",
    "# y - ЦЕЛЕВАЯ ПЕРЕМЕННАЯ ОБУЧЕНИЯ. \n",
    "# Выделяем таргет для объектов, на которых проводим обучение\n",
    "y = df_preproc_train['target'] \n",
    "##########################################################################\n",
    "\n",
    "# МАТРИЦА ПРИЗНАКОВ ДАННЫХ ДЛЯ ТЕСТИРОВАНИЯ. \n",
    "X_ftest=df_preproc_valid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и выбор лучшей метрики ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNDState = 99 #сид рандома"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение:0.8548927585681999 \n",
      "Лучшие гиперпараметры системы: KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Определим наилучшие гиперпараметры для данного алгоритма\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': randint (2, 5),\n",
    "    'metric': ['euclidean', 'minkowski'],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "\n",
    "# Будем делать 3 запуска поиска, т.к. при большем количеств система зависает\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RNDState, shuffle=True)\n",
    "\n",
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "random_search_knn = RandomizedSearchCV(model_knn, param_distributions=param_grid, n_iter=3, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=RNDState)\n",
    "#fit()\n",
    "random_search_knn.fit(X, y)\n",
    "\n",
    "\n",
    "print (\"Лучшее значение:{} \".format(random_search_knn.best_score_))\n",
    "print (\"Лучшие гиперпараметры системы: {}\".format(random_search_knn.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево принятия решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение:0.9366018078137105 \n",
      "Лучшие гиперпараметры системы: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "            max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=9, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=99,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Определим пространство поиска\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(2, 8),\n",
    "    'min_samples_leaf': randint(5, 10),\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "# Будем делать 200 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RNDState, shuffle=True)\n",
    "\n",
    "model_dtc = DecisionTreeClassifier(random_state=RNDState)\n",
    "random_search_dtc = RandomizedSearchCV(model_dtc, param_distributions=param_grid, n_iter=200, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=RNDState)\n",
    "#fit()\n",
    "random_search_dtc.fit(X, y)\n",
    "print (\"Лучшее значение:{} \".format(random_search_dtc.best_score_))\n",
    "print (\"Лучшие гиперпараметры системы: {}\".format(random_search_dtc.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение:0.929518502580553 \n",
      "Лучшие гиперпараметры системы: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=99,\n",
      "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Определим пространство поиска\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['lbfgs', 'sag', 'saga'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'multi_class': ['ovr', 'multinomial']\n",
    "    }\n",
    "\n",
    "# Будем делать 10 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RNDState, shuffle=True)\n",
    "\n",
    "model_lr = LogisticRegression(random_state=RNDState)\n",
    "random_search_lr = RandomizedSearchCV(model_lr, param_distributions=param_grid, n_iter=10, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=RNDState)\n",
    "#fit()\n",
    "random_search_lr.fit(X, y)\n",
    "print (\"Лучшее значение:{} \".format(random_search_lr.best_score_))\n",
    "print (\"Лучшие гиперпараметры системы: {}\".format(random_search_lr.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Итак, исходя из полученных данных, дерево принятия решений имеет максимальную точность предсказания. Поэтому предсказания на данных test.csv будем делать с помощью данного алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=6, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=9, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=83,\n",
    "            splitter='best')\n",
    "model_final.fit(X, y)\n",
    "#выполняем предсказания на валидационных данных\n",
    "predict = model_final.predict(X_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем список и переводим его в датафрейм\n",
    "predict_result_list=list(zip(df_sample['_id'], predict))\n",
    "predict_result = pd.DataFrame(predict_result_list, columns=['_id','target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение в csv\n",
    "predict_result.to_csv('file.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

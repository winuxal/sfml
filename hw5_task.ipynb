{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs # Чтобы не было проблем с кодировками.\n",
    "import pymorphy2 # Морфологический анализатор.\n",
    "import operator #для сортировки словаря\n",
    "\n",
    "#=========библиотеки для подбора гиперпараметров============\n",
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import GridSearchCV\n",
    "    from sklearn.cross_validation import RandomizedSearchCV\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "#===========================================================\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import validation_curve\n",
    "except ImportError:\n",
    "    from sklearn.learning_curve import validation_curve\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "    \n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', sep='\\t')\n",
    "df_test = pd.read_csv('test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем теги\n",
    "def del_tags(df_init) -> list:\n",
    "    texts_without_tags = []\n",
    "    for t in df_init['description']:\n",
    "        texts_without_tags.append(\n",
    "            BeautifulSoup(t, 'lxml').text\n",
    "        )\n",
    "    return texts_without_tags\n",
    "\n",
    "# перевод в нижний регистр\n",
    "def text_lower_desc(df_init) -> list:\n",
    "    texts_lower = []\n",
    "    for t in df_init['description']:\n",
    "        texts_lower.append(\n",
    "            t.lower()\n",
    "        )\n",
    "    return texts_lower\n",
    "\n",
    "# перевод в нижний регистр\n",
    "def text_lower_name(df_init) -> list:\n",
    "    texts_lower = []\n",
    "    for t in df_init['name']:\n",
    "        texts_lower.append(t.lower())\n",
    "    return texts_lower\n",
    "\n",
    "def permit_symbol (df_init):\n",
    "    PERMITTED_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZЙЦУКЕНГШЩЗХЪЭЖДЛОРПАВЫФЯЧСМИТЬБЮЁёйцукенгшщзхъэждлорпавыфячсмитьбю \"\n",
    "    column=[]\n",
    "    len_mas_pos=df_init.count()\n",
    "    lenght = len_mas_pos[1]\n",
    "    for i in range(lenght):\n",
    "        someString = \"\".join(c for c in df_init.iloc[i].tolist()[1] if c in PERMITTED_CHARS)\n",
    "        column.append(someString)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(df_init) -> dict:\n",
    "    PERMITTED_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZЙЦУКЕНГШЩЗХЪЭЖДЛОРПАВЫФЯЧСМИТЬБЮЁёйцукенгшщзхъэждлорпавыфячсмитьбю \" \n",
    "    len_mas_pos={}\n",
    "    len_mas_pos=df_init.count()\n",
    "    length = len_mas_pos[1]\n",
    "    aim_dict=[] #массив всех слов\n",
    "    morph=pymorphy2.MorphAnalyzer()\n",
    "    for i in range(length):\n",
    "        someString_name = \"\".join(c for c in df_init.iloc[i].tolist()[1] if c in PERMITTED_CHARS)\n",
    "        #someString_descrip = \"\".join(c for c in df_init.iloc[i].tolist()[2] if c in PERMITTED_CHARS)\n",
    "        aim_dict.append(someString_name)\n",
    "        #aim_dict.append(someString_descrip)\n",
    "    word_dict = {} #преобразуем в словарь и отсортируем по убыванию\n",
    "    for text in aim_dict:\n",
    "        #text=text.lower()\n",
    "        for word in text.split():\n",
    "            if len(word)>=4:#добавим в словарь только слова, в которых более трех букв\n",
    "                #print(word)\n",
    "                wordform=morph.parse(word) \n",
    "                word=wordform[0].normal_form\n",
    "                #print(word1)\n",
    "                word_dict[word] = word_dict.get(word, 0) + 1\n",
    "    sorted_word = sorted(word_dict.items(),reverse=True, key=operator.itemgetter(1))\n",
    "    return sorted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['description'], axis=1)\n",
    "df_test=df_test.drop(['description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train.pipe(text_lower_name) \n",
    "df_test['name'] = df_test.pipe(text_lower_name) \n",
    "df_train['name'] = df_train.pipe(permit_symbol) \n",
    "df_test['name'] = df_test.pipe(permit_symbol) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_positive=df_train[df_train['target']==1]\n",
    "df_train_negative=df_train[df_train['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dictionary_positive = create_dict(df_train_positive)\n",
    "sorted_dictionary_negative = create_dict(df_train_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snv=pd.DataFrame(sorted_dictionary_negative)#Датафрейм слов из негативных вакансий [слово:количество]\n",
    "df_snv.columns = ['word', 'quantity' ]\n",
    "df_spv=pd.DataFrame(sorted_dictionary_positive)#Датафрейм слов из позитивных вакансий [слово:количество]\n",
    "df_spv.columns = ['word', 'quantity' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция нормализации. (добавляет столбец в датафрейм с частотой)\n",
    "def normalizeSet (df_init):\n",
    "    summa = df_init['quantity'].sum()\n",
    "    df_init['normal'] = df_init['quantity'].map(lambda s: s/summa)\n",
    "    return df_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snv = df_snv.pipe(normalizeSet)\n",
    "df_snv = df_snv.drop(['quantity'], axis=1)\n",
    "df_spv = df_spv.pipe(normalizeSet)\n",
    "df_spv = df_spv.drop(['quantity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict=pd.merge(df_snv, df_spv, on='word', how='outer')\n",
    "df_dict.columns = ['word', 'negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict=df_dict.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['sum']=df_dict['positive']-df_dict['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict=df_dict.drop(['negative','positive'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>продавецкассир</td>\n",
       "      <td>-0.039482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>специалист</td>\n",
       "      <td>-0.015722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>инженер</td>\n",
       "      <td>-0.021765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word       sum\n",
       "0  продавецкассир -0.039482\n",
       "1      специалист -0.015722\n",
       "2         инженер -0.021765"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict.head(3) #СЛОВАРЬ ВЕСОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Теперь пройдемся по тестовым данным и заменим известные слова на их вес. \n",
    "#Неизвестные слова = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# ТРЕЙНОВЫЕ ДАННЫЕ\n",
    "#Приведение слов к нормальной форме \n",
    "len_df=df_train.count().tolist()\n",
    "len_df[0]\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "for i in range(len_df[0]):\n",
    "    string_df=df_train['name'][i].split()\n",
    "    length_string=len(string_df)\n",
    "    string_new_df=[]\n",
    "    for x in range(length_string):\n",
    "        word=string_df[x]\n",
    "        wordform=morph.parse(word) \n",
    "        word=wordform[0].normal_form\n",
    "        string_new_df.append(word)\n",
    "    df_train['name'][i]=' '.join(string_new_df)\n",
    "\n",
    "#сумма весов слов по строкам датафрейма\n",
    "df_train[\"sum\"] = np.nan\n",
    "len_df=df_train.count().tolist()\n",
    "len_df[0]\n",
    "\n",
    "for i in range(len_df[0]):\n",
    "    string_df=df_train['name'][i].split()\n",
    "    length_string=len(string_df)\n",
    "    sum=0\n",
    "    for x in range(length_string):\n",
    "        try:\n",
    "            index=df_dict.loc[df_dict['word'] == string_df[x],['sum']].index[0]\n",
    "            sum=sum+df_dict.loc[index, 'sum']\n",
    "        except IndexError:\n",
    "            k=0\n",
    "        df_train['sum'][i]=sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# ТЕСТОВЫЕ ДАННЫЕ\n",
    "#Приведение слов к нормальной форме\n",
    "len_df=df_test.count().tolist()\n",
    "len_df[0]\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "for i in range(len_df[0]):\n",
    "    string_df=df_test['name'][i].split()\n",
    "    length_string=len(string_df)\n",
    "    string_new_df=[]\n",
    "    for x in range(length_string):\n",
    "        word=string_df[x]\n",
    "        wordform=morph.parse(word) \n",
    "        word=wordform[0].normal_form\n",
    "        string_new_df.append(word)\n",
    "    df_test['name'][i]=' '.join(string_new_df)\n",
    "       \n",
    "#сумма весов слов по строкам датафрейма\n",
    "df_test[\"sum\"] = np.nan\n",
    "len_df=df_test.count().tolist()\n",
    "len_df[0]\n",
    "\n",
    "for i in range(len_df[0]):\n",
    "    string_df=df_test['name'][i].split()\n",
    "    length_string=len(string_df)\n",
    "    sum=0\n",
    "    for x in range(length_string):\n",
    "        try:\n",
    "            index=df_dict.loc[df_dict['word'] == string_df[x],['sum']].index[0]\n",
    "            sum=sum+df_dict.loc[index, 'sum']\n",
    "        except IndexError:\n",
    "            k=0\n",
    "        df_test['sum'][i]=sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>target</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>заведовать отделомсекция в магазин york уручей</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>наладчик станок и манипулятор с пу</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>разработчик с криптограф</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            name  target       sum\n",
       "0   0  заведовать отделомсекция в магазин york уручей       1  0.019245\n",
       "1   1              наладчик станок и манипулятор с пу       0 -0.004648\n",
       "2   2                        разработчик с криптограф       0 -0.014608"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>дизайнерконсультант мебель</td>\n",
       "      <td>0.005973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>продавецконсультант тц на пушкин</td>\n",
       "      <td>0.044248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>менеджер по продажа</td>\n",
       "      <td>0.203751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                              name       sum\n",
       "0  200000        дизайнерконсультант мебель  0.005973\n",
       "1  200001  продавецконсультант тц на пушкин  0.044248\n",
       "2  200002               менеджер по продажа  0.203751"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('file_train_all_column.csv', sep=',')\n",
    "df_test = pd.read_csv('file_test_all_column.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>target</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>заведовать отделомсекция в магазин york уручей</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            name  target       sum\n",
       "0   0  заведовать отделомсекция в магазин york уручей       1  0.019276"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>дизайнерконсультант мебель</td>\n",
       "      <td>0.004182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        name       sum\n",
       "0  200000  дизайнерконсультант мебель  0.004182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['target_my','quant'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop(['target','quant'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные к виду, необходимому для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если при вычислении получилось, что столбец суммы пуст, то удалим их\n",
    "df_train = df_train[~df_train['sum'].isnull()] \n",
    "df_test = df_test.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df_init):\n",
    "    df_output= df_init.copy()\n",
    "    # Удалим ненужные признаки\n",
    "    df_output = df_output.drop(['id', 'name'], axis=1)\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc_train = df_train.pipe(preproc) #получили необходимый для обучения датасет\n",
    "df_preproc_valid = df_test.pipe(preproc) #получили датасет для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X - МАТРИЦА ПРИЗНАКОВ ДАННЫХ ДЛЯ ОБУЧЕНИЯ.\n",
    "# Удаляем таргет из фичей объектов, на которых проходим обучение\n",
    "X=df_preproc_train.drop('target', axis=1) \n",
    "# y - ЦЕЛЕВАЯ ПЕРЕМЕННАЯ ОБУЧЕНИЯ. \n",
    "# Выделяем таргет для объектов, на которых проводим обучение\n",
    "y = df_preproc_train['target'] \n",
    "##########################################################################\n",
    "# МАТРИЦА ПРИЗНАКОВ ДАННЫХ ДЛЯ ТЕСТИРОВАНИЯ. \n",
    "X_ftest=df_preproc_valid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и выбор лучшей метрики ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNDState = 99 #сид рандома"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение:0.9590509490584364 \n",
      "Лучшие гиперпараметры системы: KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Определим наилучшие гиперпараметры для данного алгоритма\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': randint (2, 5),\n",
    "    'metric': ['euclidean', 'minkowski'],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "\n",
    "# Будем делать 3 запуска поиска, т.к. при большем количеств система зависает\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RNDState, shuffle=True)\n",
    "\n",
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "random_search_knn = RandomizedSearchCV(model_knn, param_distributions=param_grid, n_iter=3, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=RNDState)\n",
    "#fit()\n",
    "random_search_knn.fit(X, y)\n",
    "\n",
    "\n",
    "print (\"Лучшее значение:{} \".format(random_search_knn.best_score_))\n",
    "print (\"Лучшие гиперпараметры системы: {}\".format(random_search_knn.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево принятия решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение:0.9604396953479246 \n",
      "Лучшие гиперпараметры системы: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "            max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=99,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Определим пространство поиска\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(2, 8),\n",
    "    'min_samples_leaf': randint(5, 10),\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "# Будем делать 200 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RNDState, shuffle=True)\n",
    "\n",
    "model_dtc = DecisionTreeClassifier(random_state=RNDState)\n",
    "random_search_dtc = RandomizedSearchCV(model_dtc, param_distributions=param_grid, n_iter=200, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=RNDState)\n",
    "#fit()\n",
    "random_search_dtc.fit(X, y)\n",
    "print (\"Лучшее значение:{} \".format(random_search_dtc.best_score_))\n",
    "print (\"Лучшие гиперпараметры системы: {}\".format(random_search_dtc.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение:0.8894176589896277 \n",
      "Лучшие гиперпараметры системы: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=99,\n",
      "          solver='saga', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Определим пространство поиска\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['lbfgs', 'sag', 'saga'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'multi_class': ['ovr', 'multinomial']\n",
    "    }\n",
    "\n",
    "# Будем делать 10 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RNDState, shuffle=True)\n",
    "\n",
    "model_lr = LogisticRegression(random_state=RNDState)\n",
    "random_search_lr = RandomizedSearchCV(model_lr, param_distributions=param_grid, n_iter=10, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=RNDState)\n",
    "#fit()\n",
    "random_search_lr.fit(X, y)\n",
    "print (\"Лучшее значение:{} \".format(random_search_lr.best_score_))\n",
    "print (\"Лучшие гиперпараметры системы: {}\".format(random_search_lr.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, исходя из полученных данных, дерево принятия решений имеет максимальную точность предсказания. Поэтому предсказания на данных test.csv будем делать с помощью данного алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=7, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=99,\n",
    "            splitter='best')\n",
    "model_final.fit(X, y)\n",
    "#выполняем предсказания на валидационных данных\n",
    "predict = model_final.predict_proba(X_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем список и переводим его в датафрейм\n",
    "predict_result_list=list(zip(df_test['id'], predict[:,1]))\n",
    "predict_result = pd.DataFrame(predict_result_list, columns=['id','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение в csv\n",
    "predict_result.to_csv('file.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
